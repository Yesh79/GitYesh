{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-06 00:00:00+05:30\n",
      "2019-01-13 00:00:00+05:30\n",
      "2019-01-20 00:00:00+05:30\n",
      "2019-01-27 00:00:00+05:30\n",
      "2019-02-03 00:00:00+05:30\n",
      "2019-02-10 00:00:00+05:30\n",
      "2019-02-17 00:00:00+05:30\n",
      "2019-02-24 00:00:00+05:30\n",
      "2019-03-03 00:00:00+05:30\n",
      "2019-03-10 00:00:00+05:30\n",
      "2019-03-17 00:00:00+05:30\n",
      "2019-03-24 00:00:00+05:30\n",
      "2019-03-31 00:00:00+05:30\n",
      "2019-04-07 00:00:00+05:30\n",
      "2019-04-14 00:00:00+05:30\n",
      "2019-04-21 00:00:00+05:30\n",
      "2019-04-28 00:00:00+05:30\n",
      "2019-05-05 00:00:00+05:30\n",
      "2019-05-12 00:00:00+05:30\n",
      "2019-05-19 00:00:00+05:30\n",
      "2019-05-26 00:00:00+05:30\n",
      "2019-06-02 00:00:00+05:30\n",
      "2019-06-09 00:00:00+05:30\n",
      "2019-06-16 00:00:00+05:30\n",
      "2019-06-23 00:00:00+05:30\n",
      "2019-06-30 00:00:00+05:30\n",
      "2019-07-07 00:00:00+05:30\n",
      "2019-07-14 00:00:00+05:30\n",
      "2019-07-21 00:00:00+05:30\n",
      "2019-07-28 00:00:00+05:30\n",
      "2019-08-04 00:00:00+05:30\n",
      "2019-08-11 00:00:00+05:30\n",
      "2019-08-18 00:00:00+05:30\n",
      "2019-08-25 00:00:00+05:30\n",
      "2019-09-01 00:00:00+05:30\n",
      "2019-09-08 00:00:00+05:30\n",
      "2019-09-15 00:00:00+05:30\n",
      "2019-09-22 00:00:00+05:30\n",
      "2019-09-29 00:00:00+05:30\n",
      "2019-10-06 00:00:00+05:30\n",
      "2019-10-13 00:00:00+05:30\n",
      "2019-10-20 00:00:00+05:30\n",
      "2019-10-27 00:00:00+05:30\n",
      "2019-11-03 00:00:00+05:30\n",
      "2019-11-10 00:00:00+05:30\n",
      "2019-11-17 00:00:00+05:30\n",
      "2019-11-24 00:00:00+05:30\n",
      "2019-12-01 00:00:00+05:30\n",
      "2019-12-08 00:00:00+05:30\n",
      "2019-12-15 00:00:00+05:30\n",
      "2019-12-22 00:00:00+05:30\n",
      "2019-12-29 00:00:00+05:30\n"
     ]
    }
   ],
   "source": [
    "#Create a Datatime index containing all the weekdays days of year 2019 and assign a random number to each of them in a dataframe\n",
    "\n",
    "# importing pandas as pd \n",
    "import pandas as pd\n",
    "  \n",
    "WD = pd.date_range(start ='1-1-2019', end ='31-12-2019', freq ='W', tz = 'Asia/Calcutta') \n",
    "  \n",
    "for val in WD: \n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   height  weight\n",
       "0      23      71\n",
       "1      42      32\n",
       "2      55      48"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Given Pandas series , height = [23,42,55] and weight = [71,32,48] . Create a dataframe with height and weight as column names\n",
    "\n",
    "df1 = pd.DataFrame({'height': [23, 42, 55], 'weight':[71, 32, 48]})\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    3\n",
       "2    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How to get the items of series A not present in series B .From ser1 remove items present in ser2\n",
    "\n",
    "serA = pd.Series([2, 3, 4, 5])\n",
    "serB = pd.Series([5, 6, 7, 8])\n",
    "\n",
    "serA[~serA.isin(serB)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Titanic Dataset\n",
    "\n",
    "df10 = pd.read_csv(r'D:\\Learning\\End to End Data Science\\Data Sets\\titanic.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compute the minimum, 25th percentile, median, 75th, and maximum of age in titanic dataset\n",
    "df10.Age.agg(min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    714.000000\n",
       "mean      29.699118\n",
       "std       14.526497\n",
       "min        0.420000\n",
       "25%       20.125000\n",
       "50%       28.000000\n",
       "max       80.000000\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df10.Age.describe(percentiles=[0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df10.Age.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df10.Age.agg(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    714.000000\n",
       "mean      29.699118\n",
       "std       14.526497\n",
       "min        0.420000\n",
       "50%       28.000000\n",
       "75%       38.000000\n",
       "max       80.000000\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df10.Age.describe(percentiles=[0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    608\n",
       "1    209\n",
       "2     28\n",
       "4     18\n",
       "3     16\n",
       "8      7\n",
       "5      5\n",
       "Name: SibSp, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How to get frequency counts of unique items of a series? Calculate the frequency counts of ‘SibSp’ column in titanic Dataset\n",
    "\n",
    "df10.SibSp.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          S\n",
       "1          C\n",
       "2          S\n",
       "3          S\n",
       "4          S\n",
       "5      Other\n",
       "6          S\n",
       "7          S\n",
       "8          S\n",
       "9          C\n",
       "10         S\n",
       "11         S\n",
       "12         S\n",
       "13         S\n",
       "14         S\n",
       "15         S\n",
       "16     Other\n",
       "17         S\n",
       "18         S\n",
       "19         C\n",
       "20         S\n",
       "21         S\n",
       "22     Other\n",
       "23         S\n",
       "24         S\n",
       "25         S\n",
       "26         C\n",
       "27         S\n",
       "28     Other\n",
       "29         S\n",
       "       ...  \n",
       "861        S\n",
       "862        S\n",
       "863        S\n",
       "864        S\n",
       "865        S\n",
       "866        C\n",
       "867        S\n",
       "868        S\n",
       "869        S\n",
       "870        S\n",
       "871        S\n",
       "872        S\n",
       "873        S\n",
       "874        C\n",
       "875        C\n",
       "876        S\n",
       "877        S\n",
       "878        S\n",
       "879        C\n",
       "880        S\n",
       "881        S\n",
       "882        S\n",
       "883        S\n",
       "884        S\n",
       "885    Other\n",
       "886        S\n",
       "887        S\n",
       "888        S\n",
       "889        C\n",
       "890    Other\n",
       "Name: Embarked, Length: 891, dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Keep only top 2 most frequent values as it is and replace everything else as ‘Other’ in ‘Embarked’ column of titanic dataset\n",
    "\n",
    "df10.Embarked.value_counts()\n",
    "df10.Embarked.replace(['Q'],'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.0, 10.0]      184\n",
       "(22.0, 40.0]     180\n",
       "(-1.0, 8.0]      179\n",
       "(40.0, 512.0]    176\n",
       "(10.0, 22.0]     172\n",
       "Name: Fare, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Bin the price column in titanic data set into 5 equal groups and get counts of each bin\n",
    "pd.qcut(df['Fare'], q=5, precision=0).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count the number of missing values in each column?\n",
    "df10.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.5"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the row number of the 5th largest value in the Age column of titanic dataset?\n",
    "\n",
    "df10.nlargest(5,['Age'])\n",
    "df10.Age.nlargest(5).iloc[-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize all columns in a dataframe?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the indices of items of ser2 in ser1 as a list.\n",
    "ser1 = pd.Series([10,9,6,5,3,1,12,8,13])\n",
    "ser2 = pd.Series([1,3,10,13])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to convert a series of date-strings to a timeseries?\n",
    "df11 = ['01Jan2010','02-02-2011','20120303','2013/04/04','2014-05-05','2015-06-06T12:20']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the day of month, week number, day of year and day of week from ser.\n",
    "#ser = pd.series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.16590212458495\n"
     ]
    }
   ],
   "source": [
    "#Compute the euclidean distance between series (points) p and q, without using a packaged formula.\n",
    "\n",
    "#Desired output = 18.165\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "p = pd.Series([1,2,3,4,5,6,7,8,9,10])\n",
    "q = pd.Series([10,9,8,7,6,5,4,3,2,1])\n",
    "print (np.linalg.norm(p-q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2000-01-07', '2000-01-14', '2000-01-21', '2000-01-28',\n",
      "               '2000-02-04', '2000-02-11', '2000-02-18', '2000-02-25',\n",
      "               '2000-03-03', '2000-03-10'],\n",
      "              dtype='datetime64[ns]', freq='W-FRI')\n"
     ]
    }
   ],
   "source": [
    "#How to create a TimeSeries starting ‘2000-01-01’ and 10 weekends (saturdays/sundays)\n",
    "\n",
    "data = pd.date_range('2000-01-01', periods = 10, freq = 'W-FRI')\n",
    "print (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import every 50th row of BostonHousing dataset as a dataframe."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
